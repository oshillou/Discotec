{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961be72-0643-4f21-95d1-790c5c5a8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4af80-ce11-418f-888e-8bae9e45698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"Synthetic datasets\"\n",
    "baseline_folder=os.path.join(root_folder, \"baseline\")\n",
    "results_folder=os.path.join(root_folder, \"results\")\n",
    "constraint_folder = os.path.join(root_folder, \"constraints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596320eb-2289-42e8-a76a-95626f88806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.concat([pd.read_csv(result_file) for result_file in glob(os.path.join(results_folder,\"*.csv\"))], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b5acb-1a44-452d-a1ae-8bee2289dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To allow comparison of the case where all models are blended together, we must add the \"mix\" case to the \n",
    "# baseline scores\n",
    "baseline_df = pd.concat([pd.read_csv(baseline_file) for baseline_file in glob(os.path.join(baseline_folder,\"*.csv\"))], ignore_index=True)\n",
    "baseline_df = baseline_df[baseline_df.Score!=\"ARI\"]\n",
    "mix_baseline_df= baseline_df.groupby([\"Dataset\",\"Model\"],as_index=False).Run.nunique()\n",
    "mix_baseline_df[\"Run\"] = mix_baseline_df.groupby([\"Dataset\"])[\"Run\"].cumsum()-mix_baseline_df[\"Run\"]\n",
    "mix_baseline_df=pd.merge(baseline_df, mix_baseline_df.rename(columns={\"Run\":\"Offset\"}), on=[\"Dataset\",\"Model\"], how=\"left\")\n",
    "mix_baseline_df[\"Run\"] = mix_baseline_df[\"Run\"]+mix_baseline_df[\"Offset\"]\n",
    "mix_baseline_df[\"Model\"] = \"mix\"\n",
    "baseline_df = pd.concat([baseline_df, mix_baseline_df.drop(\"Offset\", axis=1)], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf719ec-c353-4302-8aa4-c2d3374175aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([baseline_df, scores_df], axis=0, ignore_index=True)\n",
    "constraints_df = pd.concat([pd.read_csv(constraint_file) for constraint_file in glob(os.path.join(constraint_folder, \"*.csv\"))], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e257fc4-a6f6-4efc-9f6d-37db49617fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation_table(df, index=[\"Dataset\"], target=\"ARI\", correlation_method=\"pearson\"):\n",
    "    # First, we pivot the dataset to get all the scores on the columns (ie as variables)\n",
    "    pivoted_df = df.pivot(columns=\"Score\",index=[\"Dataset\",\"Run\",\"Model\"], values=\"Value\").reset_index()\n",
    "\n",
    "    # Then, we drop irrelevant columns and perform correlation after a grouping operation\n",
    "    columns_to_drop = [x for x in df.columns if x not in index+[target, \"Score\", \"Value\"]]\n",
    "    df = pivoted_df.drop(columns_to_drop, axis=1).groupby(index).corr(method=correlation_method)\n",
    "\n",
    "    # Then, we can pivot the dataframe to get all different scores on the columns\n",
    "    df = df[target].reset_index().rename(columns={target:\"Correlation\"})\n",
    "    df = df.pivot(columns=\"Score\", index=index, values=\"Correlation\")\n",
    "\n",
    "    # We do not forget to drop the column containing the target (correlation with itself=1)\n",
    "    df=df.drop(target, axis=1)\n",
    "\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e77234-338d-4303-b528-3cfb750dd53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target_table(df, index=[\"Dataset\"], target=\"ARI\"):\n",
    "    # We must first reduce the dataframe to the best model according to each metric\n",
    "    best_df = df.loc[df.groupby(index+[\"Score\"])[\"Value\"].idxmax().dropna()].drop(\"Value\",axis=1)\n",
    "    target_df = df[df.Score==target].drop(\"Score\", axis=1)\n",
    "\n",
    "    # We can then merge the dataframe with itself to get the corresponding target value\n",
    "    keys = [x for x in df.columns if x not in [\"Score\",\"Value\"]]\n",
    "    best_df = pd.merge(best_df, target_df)\n",
    "\n",
    "    # We can then pivot the dataframe while tossing away irrelevant identifying columns\n",
    "    columns_to_drop = [x for x in df.columns if x not in index+[target, \"Score\", \"Value\"]]\n",
    "    best_df = best_df.drop(columns_to_drop,axis=1)\n",
    "    pivoted_df = best_df.pivot(columns=\"Score\",index=index, values=\"Value\").reset_index()\n",
    "\n",
    "    # We drop the target variable\n",
    "    pivoted_df = pivoted_df.drop(target, axis=1)\n",
    "\n",
    "    return pivoted_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2f4b1-5963-47f7-abc0-260343cc7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regret(df, index=[\"Dataset\"]):\n",
    "    # We simply identify the best value per row\n",
    "    score_columns = [x for x in df.columns if x not in index]\n",
    "    best_scores = df[score_columns].max(1)\n",
    "\n",
    "    # And then we subtract (notice the - to get \"max - value\")\n",
    "    regret_scores = -df[score_columns].sub(best_scores, axis=0)\n",
    "    regret_scores[index] = df[index]\n",
    "\n",
    "    return regret_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a749a43-fd3a-4eda-8992-2d9238b72f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_table(df):\n",
    "    if \"Dataset\" in df.columns:\n",
    "        df = df.drop(\"Dataset\", axis=1)\n",
    "    aggregator = lambda x: f\"{x.mean():.2f}\"+\"\\\\std{\"+f\"{x.std():.2f}\"+\"}\"\n",
    "    return df.groupby(\"Model\").agg(aggregator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6b588-b101-4859-811e-4b40297ff010",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80158eb-8a7d-4481-8059-a823c26381a9",
   "metadata": {},
   "source": [
    "## Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e051ebe-a685-458e-b696-c77f925bca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First table: the correlation\n",
    "correlation_df = compute_correlation_table(df, index=[\"Dataset\", \"Model\"], correlation_method=\"pearson\")\n",
    "result = aggregate_table(correlation_df)\n",
    "display(result.T)\n",
    "print(result.T.to_latex())\n",
    "\n",
    "# Then, we can compute the regret on this correlation\n",
    "correlation_regret = compute_regret(correlation_df, index=[\"Dataset\", \"Model\"])\n",
    "result = aggregate_table(correlation_regret)\n",
    "display(result.T)\n",
    "print(result.T.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ac67ad-6de5-4598-a26a-ebddee5e92c9",
   "metadata": {},
   "source": [
    "## Kendall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd15b15-cb60-4bc2-ab44-220da2b4c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First table: the correlation\n",
    "correlation_df = compute_correlation_table(df, index=[\"Dataset\", \"Model\"], correlation_method=\"kendall\")\n",
    "result = aggregate_table(correlation_df)\n",
    "display(result.T)\n",
    "print(result.T.to_latex())\n",
    "\n",
    "# Then, we can compute the regret on this correlation\n",
    "correlation_regret = compute_regret(correlation_df, index=[\"Dataset\", \"Model\"])\n",
    "result = aggregate_table(correlation_regret)\n",
    "display(result.T)\n",
    "print(result.T.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a45d74-01ce-4c46-8705-95ec64032ec2",
   "metadata": {},
   "source": [
    "# ARI of best model per score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24cccd-c064-4f03-bc8e-8c1eec7d8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = compute_target_table(df, index=[\"Dataset\", \"Model\"])\n",
    "\n",
    "# Then, we can compute the regret on this correlation\n",
    "best_regret = compute_regret(best_df, index=[\"Dataset\", \"Model\"])\n",
    "result = aggregate_table(best_regret)\n",
    "display(result.T)\n",
    "print(result.T.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
